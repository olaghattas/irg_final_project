{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e1c9c8a",
   "metadata": {},
   "source": [
    "### Use pyserini to retrieve relevant data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4d926468",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/olagh48652/irg_course_assig/irg-programming/irg-env/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_from_disk\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36d14d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = load_from_disk(\"LitSearch_corpus_clean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a233a7e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Saved corpus.jsonl for Pyserini indexing.\n"
     ]
    }
   ],
   "source": [
    "## save corpus in a way that works with pyserini\n",
    "output_dir = \"corpus_jsonl\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "output_path = os.path.join(output_dir, \"corpus.jsonl\")\n",
    "\n",
    "with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    for item in corpus[\"full\"]:\n",
    "        doc_id = str(item[\"corpusid\"])\n",
    "        contents = (item[\"title\"] or \"\") + \" \" + (item[\"abstract\"] or \"\")\n",
    "        f.write(json.dumps({\"id\": doc_id, \"contents\": contents}) + \"\\n\")\n",
    "\n",
    "print(\" Saved corpus.jsonl for Pyserini indexing.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-10-15 13:57:00,868 INFO  [main] index.AbstractIndexer (AbstractIndexer.java:205) - Setting log level to INFO\n",
      "2025-10-15 13:57:00,876 INFO  [main] index.AbstractIndexer (AbstractIndexer.java:208) - ============ Loading Index Configuration ============\n",
      "2025-10-15 13:57:00,877 INFO  [main] index.AbstractIndexer (AbstractIndexer.java:209) - AbstractIndexer settings:\n",
      "2025-10-15 13:57:00,878 INFO  [main] index.AbstractIndexer (AbstractIndexer.java:210) -  + DocumentCollection path: /home/olagh48652/irg_course_assig/irg_project/corpus_jsonl\n",
      "2025-10-15 13:57:00,879 INFO  [main] index.AbstractIndexer (AbstractIndexer.java:211) -  + CollectionClass: JsonCollection\n",
      "2025-10-15 13:57:00,880 INFO  [main] index.AbstractIndexer (AbstractIndexer.java:212) -  + Index path: /home/olagh48652/irg_course_assig/irg_project/pyserini_index\n",
      "2025-10-15 13:57:00,881 INFO  [main] index.AbstractIndexer (AbstractIndexer.java:213) -  + Threads: 1\n",
      "2025-10-15 13:57:00,882 INFO  [main] index.AbstractIndexer (AbstractIndexer.java:214) -  + Optimize (merge segments)? false\n",
      "2025-10-15 13:57:00,978 INFO  [main] index.IndexCollection (IndexCollection.java:246) - Using DefaultEnglishAnalyzer\n",
      "2025-10-15 13:57:00,979 INFO  [main] index.IndexCollection (IndexCollection.java:247) - Stemmer: porter\n",
      "2025-10-15 13:57:00,980 INFO  [main] index.IndexCollection (IndexCollection.java:248) - Keep stopwords? false\n",
      "2025-10-15 13:57:00,980 INFO  [main] index.IndexCollection (IndexCollection.java:249) - Stopwords file: null\n",
      "2025-10-15 13:57:01,313 INFO  [main] index.IndexCollection (IndexCollection.java:197) - IndexCollection settings:\n",
      "2025-10-15 13:57:01,314 INFO  [main] index.IndexCollection (IndexCollection.java:198) -  + Generator: DefaultLuceneDocumentGenerator\n",
      "2025-10-15 13:57:01,314 INFO  [main] index.IndexCollection (IndexCollection.java:199) -  + Language: en\n",
      "2025-10-15 13:57:01,315 INFO  [main] index.IndexCollection (IndexCollection.java:200) -  + Stemmer: porter\n",
      "2025-10-15 13:57:01,315 INFO  [main] index.IndexCollection (IndexCollection.java:201) -  + Keep stopwords? false\n",
      "2025-10-15 13:57:01,315 INFO  [main] index.IndexCollection (IndexCollection.java:202) -  + Stopwords: null\n",
      "2025-10-15 13:57:01,316 INFO  [main] index.IndexCollection (IndexCollection.java:203) -  + Store positions? true\n",
      "2025-10-15 13:57:01,316 INFO  [main] index.IndexCollection (IndexCollection.java:204) -  + Store docvectors? true\n",
      "2025-10-15 13:57:01,317 INFO  [main] index.IndexCollection (IndexCollection.java:205) -  + Store document \"contents\" field? false\n",
      "2025-10-15 13:57:01,317 INFO  [main] index.IndexCollection (IndexCollection.java:206) -  + Store document \"raw\" field? true\n",
      "2025-10-15 13:57:01,317 INFO  [main] index.IndexCollection (IndexCollection.java:207) -  + Additional fields to index: []\n",
      "2025-10-15 13:57:01,318 INFO  [main] index.IndexCollection (IndexCollection.java:208) -  + Whitelist: null\n",
      "2025-10-15 13:57:01,318 INFO  [main] index.IndexCollection (IndexCollection.java:209) -  + Pretokenized?: false\n",
      "2025-10-15 13:57:01,318 INFO  [main] index.IndexCollection (IndexCollection.java:210) -  + Codec: Lucene99\n",
      "2025-10-15 13:57:01,319 INFO  [main] index.AbstractIndexer (AbstractIndexer.java:238) - ============ Indexing Collection ============\n",
      "2025-10-15 13:57:01,322 INFO  [main] index.AbstractIndexer (AbstractIndexer.java:247) - Thread pool with 1 threads initialized.\n",
      "2025-10-15 13:57:01,323 INFO  [main] index.AbstractIndexer (AbstractIndexer.java:248) - 1 file found in /home/olagh48652/irg_course_assig/irg_project/corpus_jsonl\n",
      "2025-10-15 13:57:01,323 INFO  [main] index.AbstractIndexer (AbstractIndexer.java:249) - Starting to index...\n",
      "2025-10-15 13:57:22,394 INFO  [main] index.AbstractIndexer (AbstractIndexer.java:307) - Indexing Complete! 57,986 documents indexed\n",
      "2025-10-15 13:57:22,395 INFO  [main] index.AbstractIndexer (AbstractIndexer.java:308) - ============ Final Counter Values ============\n",
      "2025-10-15 13:57:22,395 INFO  [main] index.AbstractIndexer (AbstractIndexer.java:309) - indexed:           57,986\n",
      "2025-10-15 13:57:22,395 INFO  [main] index.AbstractIndexer (AbstractIndexer.java:310) - unindexable:            0\n",
      "2025-10-15 13:57:22,396 INFO  [main] index.AbstractIndexer (AbstractIndexer.java:311) - empty:              6,197\n",
      "2025-10-15 13:57:22,396 INFO  [main] index.AbstractIndexer (AbstractIndexer.java:312) - skipped:                0\n",
      "2025-10-15 13:57:22,396 INFO  [main] index.AbstractIndexer (AbstractIndexer.java:313) - errors:                 0\n",
      "2025-10-15 13:57:22,405 INFO  [main] index.AbstractIndexer (AbstractIndexer.java:316) - Total 57,986 documents indexed in 00:00:21\n",
      "\n",
      "WARNING: Using incubator modules: jdk.incubator.vector\n",
      "Oct 15, 2025 1:57:00 PM org.apache.lucene.store.MemorySegmentIndexInputProvider <init>\n",
      "INFO: Using MemorySegmentIndexInput with Java 21; to disable start with -Dorg.apache.lucene.store.MMapDirectory.enableMemorySegments=false\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## get index using commandline \n",
    "import subprocess\n",
    "\n",
    "index_dir = \"pyserini_index\"\n",
    "os.makedirs(index_dir, exist_ok=True)\n",
    "index_path = os.path.abspath(index_dir)\n",
    "\n",
    "cmd = [\n",
    "    \"python\", \"-m\", \"pyserini.index.lucene\",\n",
    "    \"--collection\", \"JsonCollection\",\n",
    "    \"--input\", \"/home/olagh48652/irg_course_assig/irg_project/corpus_jsonl\",\n",
    "    \"--index\", index_path,\n",
    "    \"--generator\", \"DefaultLuceneDocumentGenerator\",\n",
    "    \"--threads\", \"1\",\n",
    "    \"--storePositions\", \"--storeDocvectors\", \"--storeRaw\"\n",
    "]\n",
    "\n",
    "# Run the command\n",
    "result = subprocess.run(cmd, capture_output=True, text=True)\n",
    "\n",
    "# Print stdout and stderr\n",
    "print(result.stdout)\n",
    "print(result.stderr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3374d23a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query_0:  Are there any research papers on methods to compress large-scale language models using task-agnostic knowledge distillation techniques?\n",
      "query_1:  Are there any resources available for translating Tunisian Arabic dialect that contain both manually translated comments by native speakers and additional data augmented through methods like segmentation at stop words level?\n"
     ]
    }
   ],
   "source": [
    "dataset_query = load_from_disk(\"LitSearch_query\")\n",
    "\n",
    "query_0 = dataset_query[\"full\"][0][\"query\"]\n",
    "print(\"query_0: \", query_0)\n",
    "\n",
    "query_1 = dataset_query[\"full\"][1][\"query\"]\n",
    "print(\"query_1: \", query_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6f5513d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Oct 15, 2025 2:04:24 PM org.apache.lucene.store.MemorySegmentIndexInputProvider <init>\n",
      "INFO: Using MemorySegmentIndexInput with Java 21; to disable start with -Dorg.apache.lucene.store.MMapDirectory.enableMemorySegments=false\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Top-3 results per query written to litsearch_top3_results.jsonl\n"
     ]
    }
   ],
   "source": [
    "from pyserini.search.lucene import LuceneSearcher\n",
    "import json\n",
    "\n",
    "# Initialize BM25 searcher\n",
    "lucene_bm25_searcher = LuceneSearcher(index_path)\n",
    "lucene_bm25_searcher.set_bm25(k1=0.9, b=0.4)  # Optional tuning\n",
    "\n",
    "# Example: list of query dicts (replace with your real requests)\n",
    "requests = [\n",
    "    {\"request_id\": 1, \"query\": query_0},\n",
    "    {\"request_id\": 2, \"query\": query_1}\n",
    "]\n",
    "\n",
    "# File to save top-3 results\n",
    "output_file = \"litsearch_top3_results.jsonl\"\n",
    "\n",
    "with open(output_file, \"w\", encoding=\"utf-8\") as out_f:\n",
    "    for req in requests:\n",
    "        query_text = req[\"query\"]\n",
    "        hits = lucene_bm25_searcher.search(query_text, k=3)\n",
    "\n",
    "        top3 = [\n",
    "            {\"doc_id\": hit.docid, \"score\": hit.score, \"rank\": rank + 1}\n",
    "            for rank, hit in enumerate(hits)\n",
    "        ]\n",
    "\n",
    "        out_f.write(json.dumps({\n",
    "            \"qid\": req[\"request_id\"],\n",
    "            \"query\": query_text,\n",
    "            \"top3\": top3\n",
    "        }) + \"\\n\")\n",
    "\n",
    "print(f\"✅ Top-3 results per query written to {output_file}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "irg-env (3.10.12)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
