{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4626221e",
   "metadata": {},
   "source": [
    "## Pipeline(lnc.nn TF-IDF) No Query Expasion\n",
    "\n",
    "Please make sure you already have downloaded the \"LitSearch_corpus_clean\" and LitSearch_query\" in the dataset folder <br>\n",
    "To download dataset run getting_started/get_dataset.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6cc75e5",
   "metadata": {},
   "source": [
    "### Set all paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "610c7d63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project root directory: /home/akash/UNH/CS853_IR/Project/irg_final_project\n",
      "Dataset directory: /home/akash/UNH/CS853_IR/Project/irg_final_project/dataset\n",
      "Run files directory: /home/akash/UNH/CS853_IR/Project/irg_final_project/run_files\n",
      "Corpus path: /home/akash/UNH/CS853_IR/Project/irg_final_project/dataset/LitSearch_corpus_clean\n",
      "Query path: /home/akash/UNH/CS853_IR/Project/irg_final_project/dataset/LitSearch_query\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from datasets import load_from_disk\n",
    "from pathlib import Path\n",
    "\n",
    "project_root = os.path.abspath(os.path.join(Path.cwd(), \"..\", \"..\"))\n",
    "corpus_config= \"LitSearch_corpus_clean\"\n",
    "query_config= \"LitSearch_query\"\n",
    "dataset_dir = os.path.join(project_root, \"dataset\")\n",
    "run_dir = os.path.join(project_root, \"run_files\")\n",
    "stopwords_path = os.path.join(dataset_dir, \"stopwords.txt\")\n",
    "corpus_path = os.path.join(dataset_dir, corpus_config)\n",
    "query_path = os.path.join(dataset_dir, query_config)\n",
    "\n",
    "\n",
    "print(f\"Project root directory: {project_root}\")\n",
    "print(f\"Dataset directory: {dataset_dir}\")\n",
    "print(f\"Run files directory: {run_dir}\")\n",
    "print(f\"Corpus path: {corpus_path}\")\n",
    "print(f\"Query path: {query_path}\")\n",
    "\n",
    "import sys\n",
    "sys.path.append(project_root)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "685cdb02",
   "metadata": {},
   "source": [
    "### Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b242ad3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corpus details: Dataset({\n",
      "    features: ['corpusid', 'title', 'abstract', 'citations', 'full_paper'],\n",
      "    num_rows: 64183\n",
      "})\n",
      "Queries details: Dataset({\n",
      "    features: ['query_set', 'query', 'specificity', 'quality', 'corpusids'],\n",
      "    num_rows: 597\n",
      "})\n",
      "Number of queries loaded: 597\n"
     ]
    }
   ],
   "source": [
    "corpus_full = load_from_disk(corpus_path)['full']\n",
    "queries_full = load_from_disk(query_path)['full']\n",
    "print(f\"Corpus details: {corpus_full}\")\n",
    "print(f\"Queries details: {queries_full}\")\n",
    "\n",
    "queries = [q['query'] for q in queries_full]\n",
    "print(f\"Number of queries loaded: {len(queries)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feeda5c1",
   "metadata": {},
   "source": [
    "### TF-IDF(lnc-nnn)\n",
    "lnc > Document <br>\n",
    "nnn > Expanded Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b8b5e593",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Using incubator modules: jdk.incubator.vector\n",
      "Nov 30, 2025 5:45:49 PM org.apache.lucene.store.MemorySegmentIndexInputProvider <init>\n",
      "INFO: Using MemorySegmentIndexInput with Java 21; to disable start with -Dorg.apache.lucene.store.MMapDirectory.enableMemorySegments=false\n",
      "Running tfidf_lnc_nnn: 100%|██████████| 597/597 [17:43<00:00,  1.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote /home/akash/UNH/CS853_IR/Project/irg_final_project/run_files/tfidf_lnc_nnn.run\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from src.classes.query import Query\n",
    "from src.classes.tf_idf import TF_IDF\n",
    "from tqdm import tqdm\n",
    "\n",
    "output_run_file = \"tfidf_lnc_nnn.run\"\n",
    "runfile_method_tag = \"tfidf_lnc_nnn\"\n",
    "\n",
    "index_path = os.path.join(project_root, \"indexes\", \"pyserini_index\")\n",
    "tfidf = TF_IDF(index_path)\n",
    "os.makedirs(run_dir, exist_ok=True)\n",
    "\n",
    "\n",
    "def run_tfidf_lnc_nnn(query_texts, output_filename, method_name=\"tfidf_lnc_nnn\", k=50):\n",
    "    run_path = os.path.join(run_dir, output_filename)\n",
    "    if os.path.exists(run_path):\n",
    "        print(f\"Run file {run_path} already exists. Skipping generation.\")\n",
    "        return\n",
    "    with open(run_path, \"w\", encoding=\"utf8\") as outf:\n",
    "        for qid, text in enumerate(tqdm(query_texts, desc=f\"Running {method_name}\"), start=0):\n",
    "            q_embed = Query(text).get_nnn(index_path)\n",
    "            hits = tfidf.search(q_embed, \"lnc\", k)\n",
    "            for rank, (docid, score) in enumerate(hits, start=1):\n",
    "                outf.write(f\"{qid} Q0 {docid} {rank} {score:.6f} {method_name}\\n\")\n",
    "    print(f\"Wrote {run_path}\")\n",
    "\n",
    "# Run for original queries\n",
    "run_tfidf_lnc_nnn(queries, \"tfidf_lnc_nnn.run\")\n",
    "\n",
    "# Run for thesaurus-expanded queries\n",
    "# run_tfidf_lnc_nnn(expanded_query_texts, output_filename= output_run_file, method_name = runfile_method_tag)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5be932c8",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d7828e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary (ndcg@50)\n",
      "- tfidf_lnc_nnn: mean=0.228165, stderr=0.012864\n",
      "Summary file written to: evaluation/results/tfidf_lnc_nnn/summary_ndcg@50.csv\n"
     ]
    }
   ],
   "source": [
    "!cd ../.. && \\\n",
    "python3 evaluation/evaluate.py \\\n",
    "  --qrels evaluation/litsearch.qrel \\\n",
    "  --metric ndcg@50 \\\n",
    "  --output evaluation/results/tfidf_lnc_nnn \\\n",
    "  --runs run_files/tfidf_lnc_nnn.run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8c87c64c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary (map)\n",
      "- tfidf_lnc_nnn: mean=0.163201, stderr=0.012397\n",
      "Summary file written to: evaluation/results/tfidf_lnc_nnn/summary_map.csv\n"
     ]
    }
   ],
   "source": [
    "!cd ../.. && \\\n",
    "python3 evaluation/evaluate.py \\\n",
    "  --qrels evaluation/litsearch.qrel \\\n",
    "  --metric map \\\n",
    "  --output evaluation/results/tfidf_lnc_nnn \\\n",
    "  --runs run_files/tfidf_lnc_nnn.run"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
