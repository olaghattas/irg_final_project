{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4626221e",
   "metadata": {},
   "source": [
    "## Pipeline(Thesaurus based Query Expansion > lnc.nn TF-IDF > LLM Rerank)\n",
    "\n",
    "Please make sure you already have downloaded the \"LitSearch_corpus_clean\" and LitSearch_query\" in the dataset folder <br>\n",
    "To download dataset run getting_started/get_dataset.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6cc75e5",
   "metadata": {},
   "source": [
    "### Set all paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "610c7d63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project root directory: /home/akash/UNH/CS853_IR/Project/irg_final_project\n",
      "Dataset directory: /home/akash/UNH/CS853_IR/Project/irg_final_project/dataset\n",
      "Run files directory: /home/akash/UNH/CS853_IR/Project/irg_final_project/run_files\n",
      "Corpus path: /home/akash/UNH/CS853_IR/Project/irg_final_project/dataset/LitSearch_corpus_clean\n",
      "Query path: /home/akash/UNH/CS853_IR/Project/irg_final_project/dataset/LitSearch_query\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from datasets import load_from_disk\n",
    "from pathlib import Path\n",
    "\n",
    "project_root = os.path.abspath(os.path.join(Path.cwd(), \"..\", \"..\"))\n",
    "corpus_config= \"LitSearch_corpus_clean\"\n",
    "query_config= \"LitSearch_query\"\n",
    "dataset_dir = os.path.join(project_root, \"dataset\")\n",
    "run_dir = os.path.join(project_root, \"run_files\")\n",
    "stopwords_path = os.path.join(dataset_dir, \"stopwords.txt\")\n",
    "corpus_path = os.path.join(dataset_dir, corpus_config)\n",
    "query_path = os.path.join(dataset_dir, query_config)\n",
    "\n",
    "\n",
    "print(f\"Project root directory: {project_root}\")\n",
    "print(f\"Dataset directory: {dataset_dir}\")\n",
    "print(f\"Run files directory: {run_dir}\")\n",
    "print(f\"Corpus path: {corpus_path}\")\n",
    "print(f\"Query path: {query_path}\")\n",
    "\n",
    "import sys\n",
    "sys.path.append(project_root)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "685cdb02",
   "metadata": {},
   "source": [
    "### Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b242ad3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corpus details: Dataset({\n",
      "    features: ['corpusid', 'title', 'abstract', 'citations', 'full_paper'],\n",
      "    num_rows: 64183\n",
      "})\n",
      "Queries details: Dataset({\n",
      "    features: ['query_set', 'query', 'specificity', 'quality', 'corpusids'],\n",
      "    num_rows: 597\n",
      "})\n",
      "Number of queries loaded: 597\n"
     ]
    }
   ],
   "source": [
    "corpus_full = load_from_disk(corpus_path)['full']\n",
    "queries_full = load_from_disk(query_path)['full']\n",
    "print(f\"Corpus details: {corpus_full}\")\n",
    "print(f\"Queries details: {queries_full}\")\n",
    "\n",
    "queries = [q['query'] for q in queries_full]\n",
    "print(f\"Number of queries loaded: {len(queries)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03db7edd",
   "metadata": {},
   "source": [
    "### Query Expansion (Thesaurus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "608b2273",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "expansions_thesaurus.jsonl already exists.\n",
      "Loaded 597 expanded queries from expansions_thesaurus.jsonl\n"
     ]
    }
   ],
   "source": [
    "expansion_path = os.path.join(dataset_dir, \"expansions_thesaurus.jsonl\")\n",
    "\n",
    "# if expansions_thesaurus.jsonl already exists, load it directly\n",
    "if os.path.exists(os.path.join(dataset_dir, \"expansions_thesaurus.jsonl\")):\n",
    "    print(\"expansions_thesaurus.jsonl already exists.\")\n",
    "    import json\n",
    "    expanded_queries = []\n",
    "    with open(expansion_path, \"r\", encoding=\"utf8\") as f:\n",
    "        for line in f:\n",
    "            item = json.loads(line)\n",
    "            expanded_queries.append(item[\"expanded_query\"])\n",
    "    print(f\"Loaded {len(expanded_queries)} expanded queries from expansions_thesaurus.jsonl\")\n",
    "else:\n",
    "    from src.classes.query_expansion_thesaurus import QueryExpansionThesaurus\n",
    "    qe = QueryExpansionThesaurus(max_synonyms_per_word=3, stopwords_path=stopwords_path)\n",
    "    expanded_queries = qe.expand_queries(queries, save_path=expansion_path)\n",
    "    print(f\"Saved {len(expanded_queries)} expanded queries to expansions_thesaurus.jsonl\")\n",
    "\n",
    "# Ensure we have plain text strings for expanded queries\n",
    "expanded_query_texts = [\n",
    "    item[\"expanded_query\"] if isinstance(item, dict) else item\n",
    "    for item in expanded_queries\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feeda5c1",
   "metadata": {},
   "source": [
    "### TF-IDF(lnc-nnn)\n",
    "lnc > Document <br>\n",
    "nnn > Expanded Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b8b5e593",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Using incubator modules: jdk.incubator.vector\n",
      "Nov 30, 2025 1:03:21 AM org.apache.lucene.store.MemorySegmentIndexInputProvider <init>\n",
      "INFO: Using MemorySegmentIndexInput with Java 21; to disable start with -Dorg.apache.lucene.store.MMapDirectory.enableMemorySegments=false\n",
      "Running tfidf_lnc_nnn_ThesaurusExp: 100%|██████████| 597/597 [24:18<00:00,  2.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote /home/akash/UNH/CS853_IR/Project/irg_final_project/run_files/tfidf_lnc_nnn_ThesaurusExp.run\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from src.classes.query import Query\n",
    "from src.classes.tf_idf import TF_IDF\n",
    "from tqdm import tqdm\n",
    "\n",
    "output_run_file = \"tfidf_lnc_nnn_ThesaurusExp.run\"\n",
    "runfile_method_tag = \"tfidf_lnc_nnn_ThesaurusExp\"\n",
    "\n",
    "index_path = os.path.join(project_root, \"indexes\", \"pyserini_index\")\n",
    "tfidf = TF_IDF(index_path)\n",
    "os.makedirs(run_dir, exist_ok=True)\n",
    "\n",
    "\n",
    "def run_tfidf_lnc_nnn(query_texts, output_filename, method_name=\"tfidf_lnc_nnn\", k=50):\n",
    "    run_path = os.path.join(run_dir, output_filename)\n",
    "    if os.path.exists(run_path):\n",
    "        print(f\"Run file {run_path} already exists. Skipping generation.\")\n",
    "        return\n",
    "    with open(run_path, \"w\", encoding=\"utf8\") as outf:\n",
    "        for qid, text in enumerate(tqdm(query_texts, desc=f\"Running {method_name}\"), start=0):\n",
    "            q_embed = Query(text).get_nnn(index_path)\n",
    "            hits = tfidf.search(q_embed, \"lnc\", k)\n",
    "            for rank, (docid, score) in enumerate(hits, start=1):\n",
    "                outf.write(f\"{qid} Q0 {docid} {rank} {score:.6f} {method_name}\\n\")\n",
    "    print(f\"Wrote {run_path}\")\n",
    "\n",
    "# Run for original queries\n",
    "# run_tfidf_lnc_nnn(queries, \"tfidf_lnc_nnn.run\")\n",
    "\n",
    "# Run for thesaurus-expanded queries\n",
    "run_tfidf_lnc_nnn(expanded_query_texts, output_filename= output_run_file, method_name = runfile_method_tag)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2fd218b",
   "metadata": {},
   "source": [
    "### LLM Reranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcc5ad67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Ollama model: llama3.1:8b-instruct-q8_0-16k\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LLM reranking: 100%|██████████| 597/597 [1:08:03<00:00,  6.84s/it]\n"
     ]
    }
   ],
   "source": [
    "from src.classes.llm_reranker import LLMReranker\n",
    "\n",
    "initial_run_path = os.path.join(run_dir, \"tfidf_lnc_nnn_ThesaurusExp.run\")\n",
    "output_run_path = initial_run_path[:-4] + \"_LLM-Rerank.run\"  # append _LLM-Rerank before .run\n",
    "corpus_path = os.path.join(project_root, \"data\", \"corpus_jsonl\", \"corpus.jsonl\") # path to corpus in jsonl format\n",
    "log_path = os.path.join(project_root, \"logs\", output_run_path.split(\"/\")[-1][:-4]+\".jsonl\") # logs llm reranker activity\n",
    "\n",
    "\n",
    "reranker = LLMReranker()  # uses OLLAMA_MODEL or defaults to \"llama3.1:8b-instruct-q8_0-16k\"\n",
    "reranker.rerank_runfile(\n",
    "    initial_run_path= initial_run_path, \n",
    "    corpus_path     = corpus_path,\n",
    "    output_run_path = output_run_path,\n",
    "    queries         = expanded_query_texts,  # query list\n",
    "    log_path        = log_path,\n",
    "    top_k=20,\n",
    "    run_tag=\"tfidf_lnc_nnn_ThesaurusExp_LLM-Rerank\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5be932c8",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2d7828e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary (ndcg@50)\n",
      "- tfidf_lnc_nnn_ThesaurusExp_LLM-Rerank: mean=0.193371, stderr=0.014296\n",
      "Summary file written to: evaluation/results/lnc-nnn_ThesaurusExp_LLMRerank/summary_ndcg@50.csv\n"
     ]
    }
   ],
   "source": [
    "!cd ../.. && \\\n",
    "python3 evaluation/evaluate.py \\\n",
    "  --qrels evaluation/litsearch.qrel \\\n",
    "  --metric ndcg@50 \\\n",
    "  --output evaluation/results/lnc-nnn_ThesaurusExp_LLMRerank \\\n",
    "  --runs run_files/tfidf_lnc_nnn_ThesaurusExp_LLM-Rerank.run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8c87c64c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary (map)\n",
      "- tfidf_lnc_nnn_ThesaurusExp_LLM-Rerank: mean=0.171006, stderr=0.013663\n",
      "Summary file written to: evaluation/results/lnc-nnn_ThesaurusExp_LLMRerank/summary_map.csv\n"
     ]
    }
   ],
   "source": [
    "!cd ../.. && \\\n",
    "python3 evaluation/evaluate.py \\\n",
    "  --qrels evaluation/litsearch.qrel \\\n",
    "  --metric map \\\n",
    "  --output evaluation/results/lnc-nnn_ThesaurusExp_LLMRerank \\\n",
    "  --runs run_files/tfidf_lnc_nnn_ThesaurusExp_LLM-Rerank.run"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
