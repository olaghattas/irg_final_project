{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4626221e",
   "metadata": {},
   "source": [
    "## Ola"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6cc75e5",
   "metadata": {},
   "source": [
    "### Set all paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "610c7d63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project root directory: /home/akash/UNH/CS853_IR/Project/irg_final_project\n",
      "Dataset directory: /home/akash/UNH/CS853_IR/Project/irg_final_project/dataset\n",
      "Run files directory: /home/akash/UNH/CS853_IR/Project/irg_final_project/run_files\n",
      "Corpus path: /home/akash/UNH/CS853_IR/Project/irg_final_project/dataset/LitSearch_corpus_clean\n",
      "Query path: /home/akash/UNH/CS853_IR/Project/irg_final_project/dataset/LitSearch_query\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from datasets import load_from_disk\n",
    "from pathlib import Path\n",
    "\n",
    "project_root = os.path.abspath(os.path.join(Path.cwd(), \"..\", \"..\"))\n",
    "corpus_config= \"LitSearch_corpus_clean\"\n",
    "query_config= \"LitSearch_query\"\n",
    "dataset_dir = os.path.join(project_root, \"dataset\")\n",
    "run_dir = os.path.join(project_root, \"run_files\")\n",
    "stopwords_path = os.path.join(dataset_dir, \"stopwords.txt\")\n",
    "corpus_path = os.path.join(dataset_dir, corpus_config)\n",
    "query_path = os.path.join(dataset_dir, query_config)\n",
    "\n",
    "\n",
    "print(f\"Project root directory: {project_root}\")\n",
    "print(f\"Dataset directory: {dataset_dir}\")\n",
    "print(f\"Run files directory: {run_dir}\")\n",
    "print(f\"Corpus path: {corpus_path}\")\n",
    "print(f\"Query path: {query_path}\")\n",
    "\n",
    "import sys\n",
    "sys.path.append(project_root)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "685cdb02",
   "metadata": {},
   "source": [
    "### Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b242ad3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corpus details: Dataset({\n",
      "    features: ['corpusid', 'title', 'abstract', 'citations', 'full_paper'],\n",
      "    num_rows: 64183\n",
      "})\n",
      "Queries details: Dataset({\n",
      "    features: ['query_set', 'query', 'specificity', 'quality', 'corpusids'],\n",
      "    num_rows: 597\n",
      "})\n",
      "Number of queries loaded: 597\n"
     ]
    }
   ],
   "source": [
    "corpus_full = load_from_disk(corpus_path)['full']\n",
    "queries_full = load_from_disk(query_path)['full']\n",
    "print(f\"Corpus details: {corpus_full}\")\n",
    "print(f\"Queries details: {queries_full}\")\n",
    "\n",
    "queries = [q['query'] for q in queries_full]\n",
    "print(f\"Number of queries loaded: {len(queries)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03db7edd",
   "metadata": {},
   "source": [
    "### Query Expansion (LLM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "608b2273",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "expansions_thesaurus.jsonl already exists.\n",
      "Loaded 597 expanded queries from expansions_all_req.jsonl\n"
     ]
    }
   ],
   "source": [
    "expansion_path = os.path.join(dataset_dir, \"expansions_all_req.jsonl\")\n",
    "\n",
    "# if expansions_all_req.jsonl already exists, load it directly\n",
    "if os.path.exists(expansion_path):\n",
    "    print(\"expansions_thesaurus.jsonl already exists.\")\n",
    "    import json\n",
    "    expanded_queries = []\n",
    "    with open(expansion_path, \"r\", encoding=\"utf8\") as f:\n",
    "        for line in f:\n",
    "            item = json.loads(line)\n",
    "            expanded_queries.append(item[\"expanded_query\"])\n",
    "    print(f\"Loaded {len(expanded_queries)} expanded queries from expansions_all_req.jsonl\")\n",
    "\n",
    "# Ensure we have plain text strings for expanded queries\n",
    "expanded_query_texts = [\n",
    "    item[\"expanded_query\"] if isinstance(item, dict) else item\n",
    "    for item in expanded_queries\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2fd218b",
   "metadata": {},
   "source": [
    "### LLM Reranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dcc5ad67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Ollama model: llama3.1:8b-instruct-q8_0-16k\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LLM reranking: 100%|██████████| 596/596 [1:17:56<00:00,  7.85s/it]\n"
     ]
    }
   ],
   "source": [
    "from src.classes.llm_reranker import LLMReranker\n",
    "\n",
    "initial_run_path = os.path.join(run_dir, \"dense_expanded_100.run\") # Run file after LLM query expansion and bm25\n",
    "output_run_path = os.path.join(run_dir, \"BM25_LLMExp_DenseRetrieval_LLMRe-rank.run\")  # append _LLM-Rerank before .run\n",
    "corpus_path = os.path.join(project_root, \"data\", \"corpus_jsonl\", \"corpus.jsonl\") # path to corpus in jsonl format\n",
    "log_path = os.path.join(project_root, \"logs\", \"BM25_LLMExp_DenseRetrieval_LLMRe-rank.jsonl\") # logs llm reranker activity\n",
    "\n",
    "\n",
    "reranker = LLMReranker()  # uses OLLAMA_MODEL or defaults to \"llama3.1:8b-instruct-q8_0-16k\"\n",
    "reranker.rerank_runfile(\n",
    "    initial_run_path= initial_run_path, \n",
    "    corpus_path     = corpus_path,\n",
    "    output_run_path = output_run_path,\n",
    "    queries         = expanded_query_texts,  # query list\n",
    "    log_path        = log_path,\n",
    "    top_k=20,\n",
    "    run_tag=\"BM25_LLMExp_DenseRetrieval_LLMRe-rank\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5a35c86",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "68858d78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary (ndcg@50)\n",
      "- BM25_LLMExp_DenseRetrieval_LLMRe-rank: mean=0.380100, stderr=0.014960\n",
      "Summary file written to: evaluation/results/BM25_LLMExp_DenseRetrieval_LLMRe-rank/summary_ndcg@50.csv\n"
     ]
    }
   ],
   "source": [
    "!cd ../.. && \\\n",
    "python3 evaluation/evaluate.py \\\n",
    "  --qrels evaluation/litsearch.qrel \\\n",
    "  --metric ndcg@50 \\\n",
    "  --output evaluation/results/BM25_LLMExp_DenseRetrieval_LLMRe-rank \\\n",
    "  --runs run_files/BM25_LLMExp_DenseRetrieval_LLMRe-rank.run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "96172b1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary (map)\n",
      "- BM25_LLMExp_DenseRetrieval_LLMRe-rank: mean=0.305753, stderr=0.014883\n",
      "Summary file written to: evaluation/results/BM25_LLMExp_DenseRetrieval_LLMRe-rank/summary_map.csv\n"
     ]
    }
   ],
   "source": [
    "!cd ../.. && \\\n",
    "python3 evaluation/evaluate.py \\\n",
    "  --qrels evaluation/litsearch.qrel \\\n",
    "  --metric map \\\n",
    "  --output evaluation/results/BM25_LLMExp_DenseRetrieval_LLMRe-rank\\\n",
    "  --runs run_files/BM25_LLMExp_DenseRetrieval_LLMRe-rank.run"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
