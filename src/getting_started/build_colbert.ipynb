{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "136369ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\keith\\Desktop\\Info Retrieval\\irg_final_project\\irg-env\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../../')\n",
    "\n",
    "import faiss\n",
    "import torch\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "import nltk\n",
    "from src.classes.document import Document\n",
    "from pydantic_core import from_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "52508164",
   "metadata": {},
   "outputs": [],
   "source": [
    "CORPUS_LOCATION = \"../../data/corpus_jsonl/corpus.jsonl\"\n",
    "\n",
    "with open(CORPUS_LOCATION) as corpus_file:\n",
    "    lines = corpus_file.readlines()\n",
    "    documents = [Document.model_validate_json(line) for line in lines]\n",
    "\n",
    "k = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "24c63bcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e58d48e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\keith\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\keith\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6a2c39c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_ids = []\n",
    "corpus_sentences = []\n",
    "for doc in documents:\n",
    "    doc_sentences = nltk.sent_tokenize(doc.contents)\n",
    "    doc_ids.extend([doc.id]*len(doc_sentences))\n",
    "    corpus_sentences.extend(doc_sentences)\n",
    "doc_ids_np = np.array(doc_ids)\n",
    "corpus_sentences_np = np.array(corpus_sentences)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "83c42543",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\keith\\AppData\\Local\\Temp\\ipykernel_27660\\2032570629.py:2: DeprecationWarning: __array__ implementation doesn't accept a copy keyword, so passing copy=False failed. __array__ must implement 'dtype' and 'copy' keyword arguments. To learn more, see the migration guide https://numpy.org/devdocs/numpy_2_0_migration_guide.html#adapting-to-changes-in-the-copy-keyword\n",
      "  embeddings = np.array(model.encode(corpus_sentences_np,convert_to_tensor=True,batch_size=128,device=device).to('cpu'))\n"
     ]
    }
   ],
   "source": [
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\", device=device)\n",
    "embeddings = np.array(model.encode(corpus_sentences_np,convert_to_tensor=True,batch_size=128,device=device).to('cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b43efafe",
   "metadata": {},
   "outputs": [],
   "source": [
    "faiss.normalize_L2(embeddings)\n",
    "quantizer = faiss.IndexFlatL2(embeddings.shape[1])\n",
    "index = faiss.IndexIVFFlat(quantizer,embeddings.shape[1],embeddings.shape[0] // k)\n",
    "index.train(embeddings)\n",
    "index.add(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a0745638",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   906,    926,   3396,   6099,   6421,   7102,   7970,  14826,\n",
       "        14827,  14833,  23970,  26229,  33354,  33503,  34201,  42667,\n",
       "        42668, 192360, 201297, 223543])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = np.array(model.encode(nltk.sent_tokenize(\"robot going to 3d imaging. make better motions\")))\n",
    "D, I =index.search(query, 10)\n",
    "np.unique(I.flatten())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4113801f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('257079127', 0.6689109802246094),\n",
       " ('259108523', 0.6504673957824707),\n",
       " ('12538994', 0.5457663536071777),\n",
       " ('263909429', 0.531419038772583),\n",
       " ('258832670', 0.5285805463790894),\n",
       " ('252595883', 0.5279020071029663),\n",
       " ('257280094', 0.5250652432441711),\n",
       " ('257279944', 0.5247530937194824),\n",
       " ('256105572', 0.5152944326400757),\n",
       " ('252780848', 0.5089223384857178),\n",
       " ('226226846', 0.4998963475227356),\n",
       " ('258823353', 0.4717143774032593),\n",
       " ('263605591', 0.4712994694709778),\n",
       " ('252780361', 0.4662661552429199),\n",
       " ('53235839', 0.4593668580055237),\n",
       " ('38294295', 0.4399349093437195),\n",
       " ('4071564', 0.4391446113586426)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_doc_ids = np.unique(doc_ids_np[I.flatten()])\n",
    "corpus_sentences_np[doc_ids_np == top_doc_ids[0]]\n",
    "doc_sims = []\n",
    "for id in top_doc_ids:\n",
    "    doc_sims.append((str(id),float(max([model.similarity(query_s,embedding)  for query_s in query for embedding in embeddings[doc_ids_np==id]])))) \n",
    "doc_sims\n",
    "sorted(doc_sims, key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9cb06c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "faiss.write_index(index,\"../../indexes/colbert_index/index.faiss\")\n",
    "np.savez_compressed(\"../../indexes/colbert_index/embeddings\", embeddings = embeddings, doc_ids = doc_ids_np, sentences = corpus_sentences_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bef9c036",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyserini.index.lucene import LuceneIndexReader\n",
    "from pyserini.search.lucene import LuceneSearcher"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "irg-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
